
@misc{noauthor_thesis_nodate,
	title = {Thesis {Strategy}},
	file = {Thesis Strategy (Thesis_Guide_forms).pdf:D\:\\Documents\\studies\\ss18\\Thesis\\Literature\\Thesis Strategy (Thesis_Guide_forms).pdf:application/pdf}
}

@misc{noauthor_2_2017,
	title = {2 htc vive in same place},
	url = {http://community.viveport.com/t5/General-Vive-Discussion/2-htc-vive-in-same-place/m-p/6800#M2119},
	abstract = {How can I setup 2 htc vive with 2 PC in one room?},
	language = {en},
	urldate = {2018-04-07},
	journal = {Vive Community},
	month = apr,
	year = {2017},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\7CHSCSXL\\2.html:text/html}
}

@misc{noauthor_2_2017-1,
	title = {2 htc vive in same place},
	url = {http://community.viveport.com/t5/General-Vive-Discussion/2-htc-vive-in-same-place/m-p/6800#M2119},
	abstract = {How can I setup 2 htc vive with 2 PC in one room?},
	language = {en},
	urldate = {2018-04-07},
	journal = {Vive Community},
	month = apr,
	year = {2017},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\8L5MDQF9\\6800.html:text/html}
}

@misc{auberson_multiuservive:_2018,
	title = {{MultiuserVive}: {Example} {Multiuser} {Vive} {Unity} {Project} {Git}},
	copyright = {MIT},
	shorttitle = {{MultiuserVive}},
	url = {https://github.com/pauberson/MultiuserVive},
	urldate = {2018-04-07},
	author = {Auberson, Pascal},
	month = mar,
	year = {2018},
	note = {original-date: 2016-03-01T00:05:44Z},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\7UXGWHWV\\MultiuserVive.html:text/html}
}

@misc{felixkosmalla_calibrate_2018,
	title = {Calibrate {Physical} and {Virtual} {Rooms} --- unity-vive-reality-mapper: {A} {Unity} sample project to calibrate a model of a virtual room/object to its physical counterpart using a {HTC} {Vive}},
	shorttitle = {unity-vive-reality-mapper},
	url = {https://github.com/felixkosmalla/unity-vive-reality-mapper},
	urldate = {2018-04-07},
	author = {felixkosmalla},
	month = jan,
	year = {2018},
	note = {original-date: 2017-02-13T15:44:09Z},
	keywords = {calibration, unity3d, virtual-reality, vive},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\WGAS3Z3N\\unity-vive-reality-mapper.html:text/html}
}

@article{greenwald_cocoverse_nodate,
	title = {{CocoVerse} -- {Multi}-{User} {Framework} for {Collaboration} and {Co}-{Creation} in {Virtual} {Reality}},
	abstract = {W e present CocoVerse, a shared immersive virtual reality environment in which users interact with each other and create and manipulate virtual objects using a set of hand-based tools. Simple, intuitive interfaces make the application easy to use, and its flexible toolset facilitates constructivist and exploratory learning. The modular design of the system allows it to be easily customized for new room-scale applications.},
	language = {en},
	author = {Greenwald, Scott W and Maes, Pattie},
	pages = {2},
	file = {Greenwald and Maes - Multi-User Framework for Collaboration and Co-Crea.pdf:C\:\\Users\\bowli\\Zotero\\storage\\D6ZCWX6C\\Greenwald and Maes - Multi-User Framework for Collaboration and Co-Crea.pdf:application/pdf}
}

@misc{noauthor_cybersickness:_nodate,
	title = {Cybersickness: {Perception} of {Self}-{Motion} in {Virtual} {Environments} {\textbar} {Presence}: {Teleoperators} and {Virtual} {Environments} {\textbar} {MIT} {Press} {Journals}},
	url = {https://www-mitpressjournals-org.eaccess.ub.tum.de/doi/abs/10.1162/pres.1992.1.3.311},
	urldate = {2018-04-14},
	file = {Cybersickness\: Perception of Self-Motion in Virtual Environments | Presence\: Teleoperators and Virtual Environments | MIT Press Journals:C\:\\Users\\bowli\\Zotero\\storage\\RZFPDCKT\\pres.1992.1.3.html:text/html}
}

@article{mccauley_cybersickness:_1992,
	title = {Cybersickness: {Perception} of {Self}-{Motion} in {Virtual} {Environments}},
	volume = {1},
	issn = {1054-7460, 1531-3263},
	shorttitle = {Cybersickness},
	url = {http://www.mitpressjournals.org/doi/10.1162/pres.1992.1.3.311},
	doi = {10.1162/pres.1992.1.3.311},
	abstract = {Human perceptual systems have evolved to provide accurate information about orientation and movement through the environment. However, these systems have been challenged in the past century by modern transportation devices and will be further challenged by virtual environments (VEs) and teleoperator systems. Illusory self-motion within a VE ("cyberspace") will be entertaining and instructive, but for many users it will result in motion sickness ("cybersickness"). Sensory conflict theory and the poison hypothesis provide an unproven theoretical foundation for understanding the phenomenon. Although no single engineering solution is likely, the problem can be contained by a combination of engineering design, equipment calibration, and exposure management.},
	language = {en},
	number = {3},
	urldate = {2018-04-14},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {McCauley, Michael E. and Sharkey, Thomas J.},
	month = jan,
	year = {1992},
	pages = {311--318},
	file = {McCauley and Sharkey - 1992 - Cybersickness Perception of Self-Motion in Virtua.pdf:C\:\\Users\\bowli\\Zotero\\storage\\WSD6ZDEM\\McCauley and Sharkey - 1992 - Cybersickness Perception of Self-Motion in Virtua.pdf:application/pdf}
}

@article{greenwald_technology_2017,
	title = {Technology and {Applications} for {Collaborative} {Learning} in {Virtual} {Reality}},
	abstract = {In this symposium we explore the immense potential for virtual reality to be applied in educational settings. We discuss recent technological developments against a backdrop of several decades of research. Six presentations, including four from academic authors and two from the commercial sector, will explore user requirements, new technologies, and practical issues in collaborative VR applications for learning.},
	language = {en},
	author = {Greenwald, Scott W and Kulik, Alexander and Kunert, André and Weimar, Bauhaus-Universität and Beck, Stephan and Weimar, Bauhaus-Universität and Fröhlich, Bernd and Weimar, Bauhaus-Universität and Cobb, Sue and Parsons, Sarah and Newbutt, Nigel and Gouveia, Christine and Cook, Claire and Snyder, Anne and Payne, Scott and Holland, Jennifer and Buessing, Shawn and Fields, Gabriel and Lee, Victoria and Xia, Lei and Maes, Pattie},
	year = {2017},
	pages = {9},
	file = {Greenwald et al. - 2017 - Technology and Applications for Collaborative Lear.pdf:C\:\\Users\\bowli\\Zotero\\storage\\V3C4FYVE\\Greenwald et al. - 2017 - Technology and Applications for Collaborative Lear.pdf:application/pdf}
}

@article{potur_creative_2006,
	title = {{CREATIVE} {THINKING} {IN} {ARCHITECTURAL} {DESIGN} {EDUCATION}},
	abstract = {Creativity is an original cognitive ability and problem solving process which enables individuals to use their intelligence in a way that is unique and directed toward coming up with a product. The most common means of identifying creativity has been through its products. The arts including sculpture, painting, and the humanities including writing, law are not only areas in which human creativity has been exhibited. Science and engineering fields are also full of discoveries and products that meet our tests of creativity. Today, there is a need for measuring creativity in different fields of disciplines and professions such as personnel selection, education and fine arts. Architectural education is one of them because, it can be defined as a design study which get it’s origins from creativity. While the encouragement and rewarding of creativity is very important in all fields, it is especially important in the field of architectural education.},
	language = {en},
	journal = {Built Environment},
	author = {Potur, Ayla Ayyýldýz and Barkul, Ömür},
	year = {2006},
	pages = {13},
	file = {Potur and Barkul - 2006 - CREATIVE THINKING IN ARCHITECTURAL DESIGN EDUCATIO.pdf:C\:\\Users\\bowli\\Zotero\\storage\\NRJMBWY4\\Potur and Barkul - 2006 - CREATIVE THINKING IN ARCHITECTURAL DESIGN EDUCATIO.pdf:application/pdf}
}

@article{amireh_introduction_2013,
	title = {An {Introduction} to {Creative} {Thinking} in {Architectural} {Design}},
	volume = {13},
	abstract = {Architecture in Jordan academia and professionalism considered as an engineering not an artistic practice. Architectural education in Jordan and in particular the University of Jordan, and in the last 15 years took a dramatic trend. Number of students accepted in the first year, Department of Architecture, rise from 50 to 210, (JU 2006-2007) while their artistic skills and abilities drop dramatically. Although, scientifically most of them are highly qualified, few of them have any clue of design, creativity, way of thinking, projects problem solving, and many manual and mental skills. On the other side, architectural schools, curriculum and courses did not catch with the students growing numbers, their scientific background and low arts knowledge. Also it did not catch up with the changing architectural trends and movements, or the rapidly emerging information technology, and above all new methods, developed internationally, in ways of teaching, tools and techniques, and ways of thinking patterns and concepts. All above changes widely contradict with the conventional teaching ways. Old ways depend heavily on developing student’s manual skills, mental perception, and natural intelligence, which all prove are time and effort consuming, which neither the students numbers, nor background and qualifications affords. Within these constraints and in order to handle the students variable potentials, abilities and contradictions, certain exercises in the basic architectural design courses were devised in ways that; reduces its dependency on learnable manual skills and conceptual thinking; uses teaching techniques that correlates and incorporates Arts, Architecture and Sciences as complementary topics; approaches and reaches creativity as a procedure not a gift; transfers and travels easily between complexities and simplicities, between natural and artificial intelligence, between abstract and relative thinking; employ geometries and design tools as the main structure of any composition; makes self evaluations of choices, decisions and variables easier. Taking Abstraction as a framework in solving the problem of the exercises gave answers and solution to many problems that was not easy solving under the conventional ways of design.},
	language = {en},
	number = {05},
	journal = {International Journal of Engineering},
	author = {Amireh, Omar Musa},
	year = {2013},
	pages = {10},
	file = {Amireh - 2013 - An Introduction to Creative Thinking in Architectu.pdf:C\:\\Users\\bowli\\Zotero\\storage\\GESVDBPR\\Amireh - 2013 - An Introduction to Creative Thinking in Architectu.pdf:application/pdf}
}

@inproceedings{greenwald_investigating_2017,
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Investigating {Social} {Presence} and {Communication} with {Embodied} {Avatars} in {Room}-{Scale} {Virtual} {Reality}},
	isbn = {978-3-319-60632-3 978-3-319-60633-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-60633-0_7},
	doi = {10.1007/978-3-319-60633-0_7},
	abstract = {Room-scale virtual reality (VR) holds great potential as a medium for communication and collaboration in remote and same-time, same-place settings. Related work has established that movement realism can create a strong sense of social presence, even in the absence of photorealism. Here, we explore the noteworthy attributes of communicative interaction using embodied minimal avatars in room-scale VR in the same-time, same-place setting. Our system is the first in the research community to enable this kind of interaction, as far as we are aware. We carried out an experiment in which pairs of users performed two activities in contrasting variants: VR vs. face-to-face (F2F), and 2D vs. 3D. Objective and subjective measures were used to compare these, including motion analysis, electrodermal activity, questionnaires, retrospective think-aloud protocol, and interviews. On the whole, participants communicated effectively in VR to complete their tasks, and reported a strong sense of social presence. The system’s high fidelity capture and display of movement seems to have been a key factor in supporting this. Our results confirm some expected shortcomings of VR compared to F2F, but also some non-obvious advantages. The limited anthropomorphic properties of the avatars presented some difficulties, but the impact of these varied widely between the activities. In the 2D vs. 3D comparison, the basic affordance of freehand drawing in 3D was new to most participants, resulting in novel observations and open questions. We also present methodological observations across all conditions concerning the measures that did and did not reveal differences between conditions, including unanticipated properties of the think-aloud protocol applied to VR.},
	language = {en},
	urldate = {2018-04-16},
	booktitle = {Immersive {Learning} {Research} {Network}},
	publisher = {Springer, Cham},
	author = {Greenwald, Scott W. and Wang, Zhangyuan and Funk, Markus and Maes, Pattie},
	month = jun,
	year = {2017},
	pages = {75--90},
	file = {Greenwald et al. - 2017 - Investigating Social Presence and Communication wi.pdf:D\:\\Documents\\studies\\ss18\\Thesis\\Literature\\Greenwald et al. - 2017 - Investigating Social Presence and Communication wi.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\VM37ZWWG\\login.html:text/html}
}

@misc{noauthor_oculus_nodate,
	title = {Oculus {Best} {Practices}},
	url = {https://developer.oculus.com/design/latest/concepts/book-bp/},
	urldate = {2018-04-17},
	file = {Introduction to Best Practices:C\:\\Users\\bowli\\Zotero\\storage\\HHE7WHMG\\book-bp.html:text/html}
}

@misc{lena_real-time_nodate,
	title = {Real-time {Collaboration} over {Distance}: using {Motion} {Capture} and {VR} {Interaction} in a {Telepresence} {System}},
	author = {Lena, Streppel},
	file = {Streppel - Real-time Collaboration over Distance using Motio.pdf:D\:\\Documents\\studies\\ss18\\Thesis\\Literature\\Streppel - Real-time Collaboration over Distance using Motio.pdf:application/pdf}
}

@article{staadt_ultimate_nodate,
	title = {The {Ultimate} {Display}},
	language = {en},
	author = {Staadt, Oliver},
	pages = {2},
	file = {Staadt - The Ultimate Display.pdf:C\:\\Users\\bowli\\Zotero\\storage\\49PBSKQX\\Staadt - The Ultimate Display.pdf:application/pdf}
}

@misc{noauthor_test_nodate,
	title = {test}
}

@article{alshaer_otago_2017,
	title = {({Otago}, {Wheelchair}){Immersion} factors affecting perception and behaviour in a virtual reality power wheelchair simulator},
	volume = {58},
	issn = {00036870},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0003687016300904},
	doi = {10.1016/j.apergo.2016.05.003},
	language = {en},
	urldate = {2018-04-26},
	journal = {Applied Ergonomics},
	author = {Alshaer, Abdulaziz and Regenbrecht, Holger and O’Hare, David},
	month = jan,
	year = {2017},
	pages = {1--12},
	file = {Alshaer et al. - 2017 - Immersion factors affecting perception and behavio.pdf:C\:\\Users\\bowli\\Zotero\\storage\\JV2A5APQ\\Alshaer et al. - 2017 - Immersion factors affecting perception and behavio.pdf:application/pdf}
}

@article{noauthor_otago_nodate,
	title = {({Otago}) {Mixed} {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	url = {http://www.hci.otago.ac.nz/papers/RegenbrechtIEEEISMAR2017MixedVoxelRealities.pdf}
}

@inproceedings{regenbrecht_otagomixed_2017,
	title = {({Otago}){Mixed} {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	isbn = {978-1-5386-2943-7},
	shorttitle = {Mixed {Voxel} {Reality}},
	url = {http://ieeexplore.ieee.org/document/8115408/},
	doi = {10.1109/ISMAR.2017.26},
	abstract = {Mixed Reality aims at combining virtual reality with the user’s surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users’ embodiment is important. Our ﬁndings challenge some commonplace assumptions on “more is better“ approaches in mixed reality research and practice—sometimes less can be more.},
	language = {en},
	urldate = {2018-04-28},
	publisher = {IEEE},
	author = {Regenbrecht, Holger and Meng, Katrin and Reepen, Arne and Beck, Stephan and Langlotz, Tobias},
	month = oct,
	year = {2017},
	pages = {90--99},
	file = {Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:C\:\\Users\\bowli\\Zotero\\storage\\L7GZNHX3\\Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:application/pdf}
}

@inproceedings{regenbrecht_mixed_2017,
	title = {Mixed {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	isbn = {978-1-5386-2943-7},
	shorttitle = {Mixed {Voxel} {Reality}},
	url = {http://ieeexplore.ieee.org/document/8115408/},
	doi = {10.1109/ISMAR.2017.26},
	abstract = {Mixed Reality aims at combining virtual reality with the user’s surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users’ embodiment is important. Our ﬁndings challenge some commonplace assumptions on “more is better“ approaches in mixed reality research and practice—sometimes less can be more.},
	language = {en},
	urldate = {2018-04-28},
	publisher = {IEEE},
	author = {Regenbrecht, Holger and Meng, Katrin and Reepen, Arne and Beck, Stephan and Langlotz, Tobias},
	month = oct,
	year = {2017},
	pages = {90--99},
	file = {Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:C\:\\Users\\bowli\\Zotero\\storage\\7ZYUWNLH\\Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:application/pdf}
}

@inproceedings{regenbrecht_mixed_2017-1,
	title = {Mixed {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	isbn = {978-1-5386-2943-7},
	shorttitle = {Mixed {Voxel} {Reality}},
	url = {http://ieeexplore.ieee.org/document/8115408/},
	doi = {10.1109/ISMAR.2017.26},
	abstract = {Mixed Reality aims at combining virtual reality with the user’s surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users’ embodiment is important. Our ﬁndings challenge some commonplace assumptions on “more is better“ approaches in mixed reality research and practice—sometimes less can be more.},
	language = {en},
	urldate = {2018-04-28},
	publisher = {IEEE},
	author = {Regenbrecht, Holger and Meng, Katrin and Reepen, Arne and Beck, Stephan and Langlotz, Tobias},
	month = oct,
	year = {2017},
	pages = {90--99},
	file = {Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:C\:\\Users\\bowli\\Zotero\\storage\\G5GI5AQQ\\Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:application/pdf}
}

@inproceedings{regenbrecht_mixed_2017-2,
	title = {Mixed {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	isbn = {978-1-5386-2943-7},
	shorttitle = {Mixed {Voxel} {Reality}},
	url = {http://ieeexplore.ieee.org/document/8115408/},
	doi = {10.1109/ISMAR.2017.26},
	abstract = {Mixed Reality aims at combining virtual reality with the user’s surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users’ embodiment is important. Our ﬁndings challenge some commonplace assumptions on “more is better“ approaches in mixed reality research and practice—sometimes less can be more.},
	language = {en},
	urldate = {2018-04-28},
	publisher = {IEEE},
	author = {Regenbrecht, Holger and Meng, Katrin and Reepen, Arne and Beck, Stephan and Langlotz, Tobias},
	month = oct,
	year = {2017},
	pages = {90--99},
	file = {Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:C\:\\Users\\bowli\\Zotero\\storage\\GGQNRYMK\\Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:application/pdf}
}

@inproceedings{regenbrecht_mixed_2017-3,
	title = {Mixed {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	isbn = {978-1-5386-2943-7},
	shorttitle = {Mixed {Voxel} {Reality}},
	url = {http://ieeexplore.ieee.org/document/8115408/},
	doi = {10.1109/ISMAR.2017.26},
	abstract = {Mixed Reality aims at combining virtual reality with the user’s surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users’ embodiment is important. Our ﬁndings challenge some commonplace assumptions on “more is better“ approaches in mixed reality research and practice—sometimes less can be more.},
	language = {en},
	urldate = {2018-04-28},
	publisher = {IEEE},
	author = {Regenbrecht, Holger and Meng, Katrin and Reepen, Arne and Beck, Stephan and Langlotz, Tobias},
	month = oct,
	year = {2017},
	pages = {90--99},
	file = {Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:C\:\\Users\\bowli\\Zotero\\storage\\7N752DER\\Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:application/pdf}
}

@inproceedings{regenbrecht_mixed_2017-4,
	title = {Mixed {Voxel} {Reality}: {Presence} and {Embodiment} in {Low} {Fidelity}, {Visually} {Coherent}, {Mixed} {Reality} {Environments}},
	isbn = {978-1-5386-2943-7},
	shorttitle = {Mixed {Voxel} {Reality}},
	url = {http://ieeexplore.ieee.org/document/8115408/},
	doi = {10.1109/ISMAR.2017.26},
	abstract = {Mixed Reality aims at combining virtual reality with the user’s surrounding real environment in a way that they form one, coherent reality. A coherent visual quality is of utmost importance, expressed in measures of e.g. resolution, framerate, and latency for both the real and the virtual domains. For years, researchers have focused on maximizing the quality of the virtual visualization mimicking the real world to get closer to visual coherence. This however, makes Mixed Reality systems overly complex and requires high computational power. In this paper, we propose a different approach by decreasing the realism of one or both visual realms, real and virtual, to achieve visual coherence. Our system coarsely voxelizes the real and virtual environments, objects, and people to provide a believable, coherent mixed voxel reality. In this paper we present the general idea, the current implementation and demonstrate the effectiveness of our approach by technical and empirical evaluations. Our mixed voxel reality system serves as a platform for low-cost presence research and studies on human perception and cognition, a host of diagnostic and therapeutic applications, and for a variety of Mixed Reality applications where users’ embodiment is important. Our ﬁndings challenge some commonplace assumptions on “more is better“ approaches in mixed reality research and practice—sometimes less can be more.},
	language = {en},
	urldate = {2018-04-28},
	publisher = {IEEE},
	author = {Regenbrecht, Holger and Meng, Katrin and Reepen, Arne and Beck, Stephan and Langlotz, Tobias},
	month = oct,
	year = {2017},
	pages = {90--99},
	file = {Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:C\:\\Users\\bowli\\Zotero\\storage\\96JKDR5M\\Regenbrecht et al. - 2017 - Mixed Voxel Reality Presence and Embodiment in Lo.pdf:application/pdf}
}

@article{schubert_experience_2001,
	title = {The {Experience} of {Presence}: {Factor} {Analytic} {Insights}},
	volume = {10},
	issn = {1054-7460},
	shorttitle = {The {Experience} of {Presence}},
	url = {https://doi.org/10.1162/105474601300343603},
	doi = {10.1162/105474601300343603},
	abstract = {Within an embodied cognition framework, it is argued that presence in a virtual environment (VE) develops from the construction of a spatial-functional mental model of the VE. Two cognitive processes lead to this model: the representation of bodily actions as possible actions in the VE, and the suppression of incompatible sensory input. It is hypothesized that the conscious sense of presence reflects these two components as spatial presence and involvement. This prediction was confirmed in two studies (N = 246 and N = 296) assessing self-reports of presence and immersion experiences. Additionally, judgments of “realness” were observed as a third presence component. A second-order factor analysis showed a distinction between presence, immersion, and interaction factors. Building on these results, a thirteen-item presence scale consisting of three independent components was developed and verified using confirmatory factor analyses across the two studies.},
	number = {3},
	urldate = {2018-04-28},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Schubert, Thomas and Friedmann, Frank and Regenbrecht, Holger},
	month = jun,
	year = {2001},
	pages = {266--281},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\CAWLM3KJ\\105474601300343603.html:text/html}
}

@misc{noauthor_experimental_nodate,
	title = {Experimental {Design} {\textbar} {Simply} {Psychology}},
	url = {https://www.simplypsychology.org/experimental-designs.html},
	urldate = {2018-04-28},
	file = {Experimental Design | Simply Psychology:C\:\\Users\\bowli\\Zotero\\storage\\LC5EPH97\\experimental-designs.html:text/html}
}

@article{regenbrecht_holgermixed_2017,
	title = {({Holger}){Mixed} {Reality} {Experience} {Questionnaire} ({MREQ}) -{Reference}},
	issn = {1177-455X},
	url = {https://ourarchive.otago.ac.nz/handle/10523/7151},
	abstract = {The Mixed Reality Experience Questionnaire (MREQ) is designed to be used as a measure of a user's sense of presence and their general experienced perception of an Augmented Reality, Virtual Reality, or Augmented Virtuality environment. It consists of 33 seven-point-Likert-like items. Researchers might want to apply all or only some of those items. 
 
This Technical Report serves as a reference. Researchers who use this MREQ are asked to send their findings and/or publications to the first author and to cite this Technical Report.},
	language = {en},
	urldate = {2018-04-29},
	author = {Regenbrecht, Holger and Schubert, Thomas and Botella, Cristina and Baños, Rosa},
	month = feb,
	year = {2017},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\S5HAHFTQ\\Regenbrecht et al. - 2017 - Mixed Reality Experience Questionnaire (MREQ) -Ref.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\BAF9T4US\\7151.html:text/html}
}

@article{regenbrecht_mixed_nodate,
	title = {Mixed {Reality} {Experience} {Questionnaire} ({MREQ}) - {Reference}},
	abstract = {The Mixed Reality Experience Questionnaire (MREQ) is designed to be used as a measure of a user's sense of presence and their general experienced perception of an Augmented Reality, Virtual Reality, or Augmented Virtuality environment. It consists of 33 seven-pointLikert-like items. Researchers might want to apply all or only some of those items.},
	language = {en},
	author = {Regenbrecht, H and Botella, Cristina and Baños, Rosa M and Schubert, Thomas},
	pages = {4},
	file = {Regenbrecht et al. - Mixed Reality Experience Questionnaire (MREQ) - Re.pdf:C\:\\Users\\bowli\\Zotero\\storage\\6Y994I8H\\Regenbrecht et al. - Mixed Reality Experience Questionnaire (MREQ) - Re.pdf:application/pdf}
}

@misc{milgram_mixed_1994,
	title = {({Mixed} {Reality}){A} {Taxonomy} of {Mixed} {Reality} {Visual} {Displays}},
	url = {https://search.ieice.org/bin/summary.php?id=e77-d_12_1321},
	abstract = {This paper focuses on Mixed Reality (MR) visual displays, a particular subset of Virtual Reality (VR) related technologies that involve the merging of real and virtual worlds somewhere along the {\textless}cd02148.gif{\textgreater}virtuality continuum},
	urldate = {2018-04-29},
	author = {MILGRAM, Paul and KISHINO, Fumio},
	month = dec,
	year = {1994},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\XBAD46ZT\\summary.html:text/html}
}

@article{tamura_mr_2001,
	title = {({MR} and {Augmented} {Virtuality}){Mixed} reality: future dreams seen at the border between real and virtual worlds},
	volume = {21},
	issn = {0272-1716},
	shorttitle = {Mixed reality},
	doi = {10.1109/38.963462},
	abstract = {Mixed reality (MR) is a kind of virtual reality (VR) but a broader concept than augmented reality (AR), which augments the real world with synthetic electronic data. On the opposite side, there is a term, augmented virtuality (AV), which enhances or augments the virtual environment (VE) with data from the real world. Mixed reality covers a continuum from AR to AV. This concept embraces the definition of MR stated by Milgram and Kishino (1994). We describe some technical achievements we made in the Mixed Reality Project in Japan},
	number = {6},
	journal = {IEEE Computer Graphics and Applications},
	author = {Tamura, H. and Yamamoto, H. and Katayama, A.},
	month = nov,
	year = {2001},
	keywords = {augmented reality, augmented virtuality, Augmented virtuality, Cameras, Cities and towns, Computational modeling, Image reconstruction, Layout, Mixed Reality Project, rendering (computer graphics), Rendering (computer graphics), Robustness, Solid modeling, technical achievements, virtual environment, virtual reality, Virtual reality},
	pages = {64--70},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\bowli\\Zotero\\storage\\YNTR9T7R\\963462.html:text/html}
}

@article{kennedy_simulator_1993,
	title = {Simulator {Sickness} {Questionnaire}: {An} {Enhanced} {Method} for {Quantifying} {Simulator} {Sickness}},
	volume = {3},
	issn = {1050-8414},
	shorttitle = {Simulator {Sickness} {Questionnaire}},
	url = {https://doi.org/10.1207/s15327108ijap0303_3},
	doi = {10.1207/s15327108ijap0303_3},
	abstract = {Simulator sickness (SS) in high-fidelity visual simulators is a byproduct of modem simulation technology. Although it involves symptoms similar to those of motion-induced sickness (MS), SS tends to be less severe, to be of lower incidence, and to originate from elements of visual display and visuo-vestibular interaction atypical of conditions that induce MS. Most studies of SS to date index severity with some variant of the Pensacola Motion Sickness Questionnaire (MSQ). The MSQ has several deficiencies as an instrument for measuring SS. Some symptoms included in the scoring of MS are irrelevant for SS, and several are misleading. Also, the configural approach of the MSQ is not readily adaptable to computer administration and scoring. This article describes the development of a Simulator Sickness Questiomaire (SSQ), derived from the MSQ using a series of factor analyses, and illustrates its use in monitoring simulator performance with data from a computerized SSQ survey of 3,691 simulator hops. The database used for development included more than 1,100 MSQs, representing data from 10 Navy simulators. The SSQ provides straightforward computer or manual scoring, increased power to identify "problem" simulators, and improved diagnostic capability.},
	number = {3},
	urldate = {2018-04-29},
	journal = {The International Journal of Aviation Psychology},
	author = {Kennedy, Robert S. and Lane, Norman E. and Berbaum, Kevin S. and Lilienthal, Michael G.},
	month = jul,
	year = {1993},
	pages = {203--220},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\36E4H8G5\\Kennedy et al. - 1993 - Simulator Sickness Questionnaire An Enhanced Meth.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\LP3RZ48E\\s15327108ijap0303_3.html:text/html}
}

@misc{maes_investigating_nodate,
	title = {Investigating {Social} {Presence} and {Communication} with {Embodied} {Avatars} in {Room}-{Scale} {Virtual} {Reality}},
	url = {https://www.media.mit.edu/publications/investigating-social-presence-and-communication-with-embodied-avatars-in-room-scale-virtual-reality/},
	abstract = {Room-scale virtual reality (VR) holds great potential as a medium for communication and collaboration in remote and same-time, same-place settings. Related w...},
	urldate = {2018-04-29},
	journal = {MIT Media Lab},
	author = {Maes, Pattie},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\CZY6F67S\\investigating-social-presence-and-communication-with-embodied-avatars-in-room-scale-virtual-rea.html:text/html}
}

@misc{noauthor_definition_nodate,
	title = {Definition of {AFFORDANCE}},
	url = {https://www.merriam-webster.com/dictionary/affordance},
	abstract = {the qualities or properties of an object that define its possible uses or make clear how it can or should be used… See the full definition},
	language = {en},
	urldate = {2018-04-29},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\QJMADAFK\\affordance.html:text/html}
}

@misc{noauthor_variables_nodate,
	title = {Variables in {Your} {Science} {Fair} {Project}},
	url = {https://www.sciencebuddies.org/science-fair-projects/science-fair/variables},
	abstract = {Science fair project variables explained - A simple introduction to dependent, independent, and controlled variables},
	language = {en-US},
	urldate = {2018-04-29},
	journal = {Science Buddies},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\5NBWTYKL\\variables.html:text/html}
}

@misc{noauthor_variables_nodate-1,
	title = {Variables in {Your} {Science} {Fair} {Project}},
	url = {https://www.sciencebuddies.org/science-fair-projects/science-fair/variables},
	abstract = {Science fair project variables explained - A simple introduction to dependent, independent, and controlled variables},
	language = {en-US},
	urldate = {2018-04-29},
	journal = {Science Buddies},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\AXSZQ5NK\\variables.html:text/html}
}

@misc{noauthor_dependentindependentcontrolledvariables_nodate,
	title = {({Dependent},{Independent},{Controlled}){Variables} in {Your} {Science} {Fair} {Project}},
	url = {https://www.sciencebuddies.org/science-fair-projects/science-fair/variables},
	abstract = {Science fair project variables explained - A simple introduction to dependent, independent, and controlled variables},
	language = {en-US},
	urldate = {2018-04-29},
	journal = {Science Buddies},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\RJQAYFNJ\\variables.html:text/html}
}

@article{schubert_collaborative_nodate,
	title = {A ({Collaborative}) {Design} {Platform} for early design stages},
	abstract = {The motivation behind the CDP interdisciplinary research project is to resolve the current discrepancy between familiar, analogue ways of working in the early architectural design stages and the ever increasing use of digital tools in office practice. The project’s objective is the conception and prototypical realisation of an interactive work environment for use in the early design phases. By directly linking familiar analogue ways of working with digital computer aided design tools, the CDP represents a working environment that allows designers to work the way they are used to while making use of the potential of computers. This paper describes the first results of a design environment for supporting the conceptual phase of urban design.},
	language = {en},
	author = {Schubert, Gerhard and Artinger, Eva and Petzold, Frank and Klinker, Gudrun},
	keywords = {cdp, design, model, schubert, gerhard},
	pages = {7},
	file = {Schubert et al. - A (Collaborative) Design Platform for early design.pdf:C\:\\Users\\bowli\\Zotero\\storage\\TPWC4J2Z\\Schubert et al. - A (Collaborative) Design Platform for early design.pdf:application/pdf}
}

@inproceedings{davidson_greenspace_1996,
	title = {({GreenSpace} {II}){Collaborative} {Design} in {Virtual} {Space} - {GreenSpace} {II}: {A} {Shared} {Environment} for {Architectural} {Design} {Review}},
	shorttitle = {Collaborative {Design} in {Virtual} {Space} - {GreenSpace} {II}},
	url = {http://papers.cumincad.org/cgi-bin/works/Show?c7d4},
	abstract = {Design reviews and discussions are fundamental to the process of design. The ability to digitally represent three dimensional space in real-time is a new and potentially persuasive method for reviewing and analyzing a design proposal. The development of real-time rendering engines and network protocols supporting distributed interaction makes possible the idea of a shared virtual environment for architectural collaboration. This paper presents a system which facilitates the review of an architectural design between multiple participants who are remotely distributed.},
	urldate = {2018-05-03},
	booktitle = {Design {Computation}: {Collaboration}, {Reasoning}, {Pedagogy} [{ACADIA} {Conference} {Proceedings} / {ISBN} 1-880250-05-5] {Tucson} ({Arizona} / {USA}) {October} 31 - {November} 2, 1996, pp. 165-179},
	publisher = {CUMINCAD},
	author = {Davidson, James N. {and} Campbell},
	year = {1996},
	keywords = {virtual reality, design, architecture, vr, CVE},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\KS7P4VKT\\Davidson - 1996 - Collaborative Design in Virtual Space - GreenSpace.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\BKK9NYWE\\Show.html:text/html}
}

@inproceedings{bowman_[bh97]_1997,
	address = {New York, NY, USA},
	series = {I3D '97},
	title = {[{BH}97] {An} {Evaluation} of {Techniques} for {Grabbing} and {Manipulating} {Remote} {Objects} in {Immersive} {Virtual} {Environments}},
	isbn = {978-0-89791-884-8},
	url = {http://doi.acm.org/10.1145/253284.253301},
	doi = {10.1145/253284.253301},
	urldate = {2018-05-03},
	booktitle = {Proceedings of the 1997 {Symposium} on {Interactive} 3D {Graphics}},
	publisher = {ACM},
	author = {Bowman, Doug A. and Hodges, Larry F.},
	year = {1997},
	keywords = {vr, interaction, manipulation, selection, [BH97]},
	pages = {35--ff.},
	file = {ACM Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\NKZTU4VC\\Bowman and Hodges - 1997 - An Evaluation of Techniques for Grabbing and Manip.pdf:application/pdf}
}

@inproceedings{bowman_[bh97]_1997-1,
	title = {[{BH}97] {An} evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments},
	isbn = {978-0-89791-884-8},
	url = {http://portal.acm.org/citation.cfm?doid=253284.253301},
	doi = {10.1145/253284.253301},
	abstract = {Grabbing and manipulating virtual objects is an important user interaction for immersive virtual environments. We present implementations and discussion of six techniques which allow manipulation of remote objects. A user study of these techniques was performed which revealed their characteristics and deficiencies, and led to the development of a new class of techniques. These hybrid techniques provide distinct advantages in terms of ease of use and efficiency because they consider the tasks of grabbing and manipulation separately.},
	language = {en},
	urldate = {2018-05-03},
	publisher = {ACM Press},
	author = {Bowman, Doug A. and Hodges, Larry F.},
	year = {1997},
	keywords = {vr, manipulation, selection, [BH97], grabbing},
	pages = {35--ff.},
	file = {Bowman and Hodges - 1997 - An evaluation of techniques for grabbing and manip.pdf:C\:\\Users\\bowli\\Zotero\\storage\\YA6SW6GF\\Bowman and Hodges - 1997 - An evaluation of techniques for grabbing and manip.pdf:application/pdf}
}

@inproceedings{anderson_virtual_2003,
	address = {New York, NY, USA},
	series = {{EGVE} '03},
	title = {A {Virtual} {Environment} for {Conceptual} {Design} in {Architecture}},
	isbn = {978-1-58113-686-9},
	url = {http://doi.acm.org/10.1145/769953.769960},
	doi = {10.1145/769953.769960},
	abstract = {We present a virtual environment application that has been developed for conceptual design in architecture and seeks to emulate aspects of a typical designer's work area. The environment provides a means of creating and manipulating basic geometry using a kiosk toolbox. More importantly, the environment provides simple means for using imagery and videos developed outside of the environment for use within the environment for both information and design. A DesignStation is provided within the environment to create a work area for the designer, concentrating imagery and information associated with the design as well as an area for reflecting upon, presenting and critiquing the design process. A unique aspect of the environment is the ability to work in more than one scale simultaneously.},
	urldate = {2018-05-04},
	booktitle = {Proceedings of the {Workshop} on {Virtual} {Environments} 2003},
	publisher = {ACM},
	author = {Anderson, Lee and Esser, James and Interrante, Victoria},
	year = {2003},
	keywords = {virtual reality, architectural design, conceptual design, virtual environments, scale},
	pages = {57--63},
	file = {ACM Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\BH262WLE\\Anderson et al. - 2003 - A Virtual Environment for Conceptual Design in Arc.pdf:application/pdf}
}

@article{coburn_effectiveness_2018,
	title = {Effectiveness of an {Immersive} {Virtual} {Environment} for {Collaboration} {With} {Gesture} {Support} {Using} {Low}-{Cost} {Hardware}},
	volume = {140},
	issn = {1050-0472},
	url = {http://dx.doi.org/10.1115/1.4039006},
	doi = {10.1115/1.4039006},
	abstract = {Since the advent of modern computer-aided design software, engineers have been divorced from the highly collaborative environment previously enjoyed. Today's highly complex designs require modern software tools and the realities of a global economy often constrain engineers to remote collaboration. These conditions make it highly impractical to collaborate locally around physical models. Various approaches to creating new collaboration tools and software, which alleviate these issues, have been tried previously. However, past solutions either used expensive hardware, which is not widely available, or used standard two-dimensional (2D) monitors to share three-dimensional (3D) information. Recently, new low-cost virtual reality (VR) hardware has been introduced, which creates a highly immersive 3D experience at a tiny fraction of the cost of previous hardware. This work demonstrates an immersive collaborative environment built using a network of this hardware, which allows users to interact with gestures virtually and conducts a study to show its advantages over traditional video conferencing software.},
	number = {4},
	urldate = {2018-05-04},
	journal = {Journal of Mechanical Design},
	author = {Coburn, Joshua Q. and Salmon, John L. and Freeman, Ian},
	month = feb,
	year = {2018},
	pages = {042001--042001--9},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\LCMZ8M5H\\Coburn et al. - 2018 - Effectiveness of an Immersive Virtual Environment .pdf:application/pdf}
}

@article{fox_avatars_2015,
	title = {Avatars {Versus} {Agents}: {A} {Meta}-{Analysis} {Quantifying} the {Effect} of {Agency} on {Social} {Influence}},
	volume = {30},
	issn = {0737-0024},
	shorttitle = {Avatars {Versus} {Agents}},
	url = {https://doi.org/10.1080/07370024.2014.921494},
	doi = {10.1080/07370024.2014.921494},
	abstract = {Existing research has investigated whether virtual representations perceived to be controlled by humans (i.e., avatars) or those perceived to be controlled by computer algorithms (i.e., agents) are more influential. A meta-analysis (N = 32) examined the model of social influence in virtual environments (Blascovich, 2002) and investigated whether agents and avatars in virtual environments elicit different levels of social influence. Results indicated that perceived avatars produced stronger responses than perceived agents. Level of immersion (desktop vs. fully immersive), dependent variable type (subjective vs. objective), task type (competitive vs. cooperative vs. neutral), and actual control of the representation (human vs. computer) were examined as moderators. An interaction effect revealed that studies conducted on a desktop that used objective measures showed a stronger effect for agency than those that were conducted on a desktop but used subjective measures. Competitive and cooperative tasks showed greater agency effects than neutral tasks. Studies in which both conditions were actually human controlled showed greater agency effects than studies in which both conditions were actually computer controlled. We discuss theoretical and design implications for human–computer interaction and computer-mediated communication.},
	number = {5},
	urldate = {2018-05-04},
	journal = {Human–Computer Interaction},
	author = {Fox, Jesse and Ahn, Sun Joo (Grace) and Janssen, Joris H. and Yeykelis, Leo and Segovia, Kathryn Y. and Bailenson, Jeremy N.},
	month = sep,
	year = {2015},
	keywords = {agent, avatar},
	pages = {401--432},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\KTXLY3WN\\07370024.2014.html:text/html}
}

@article{bailenson_independent_2005,
	title = {The {Independent} and {Interactive} {Effects} of {Embodied}-{Agent} {Appearance} and {Behavior} on {Self}-{Report}, {Cognitive}, and {Behavioral} {Markers} of {Copresence} in {Immersive} {Virtual} {Environments}},
	volume = {14},
	issn = {1054-7460},
	url = {https://doi.org/10.1162/105474605774785235},
	doi = {10.1162/105474605774785235},
	abstract = {The current study examined how assessments of copresence in an immersive virtual environment are influenced by variations in how much an embodied agent resembles a human being in appearance and behavior. We measured the extent to which virtual representations were both perceived and treated as if they were human via self-report, behavioral, and cognitive dependent measures. Distinctive patterns of findings emerged with respect to the behavior and appearance of embodied agents depending on the definition and operationalization of copresence. Independent and interactive effects for appearance and behavior were found suggesting that assessing the impact of behavioral realism on copresence without taking into account the appearance of the embodied agent (and vice versa) can lead to misleading conclusions. Consistent with the results of previous research, copresence was lowest when there was a large mismatch between the appearance and behavioral realism of an embodied agent.},
	number = {4},
	urldate = {2018-05-04},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Bailenson, Jeremy N. and Swinth, Kim and Hoyt, Crystal and Persky, Susan and Dimov, Alex and Blascovich, Jim},
	month = aug,
	year = {2005},
	keywords = {perception, presence},
	pages = {379--393},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\QGKUI2NZ\\Bailenson et al. - 2005 - The Independent and Interactive Effects of Embodie.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\LENSTTMH\\105474605774785235.html:text/html}
}

@inproceedings{wolf_using_2017,
	address = {New York, NY, USA},
	series = {{MUM} '17},
	title = {Using {Virtual} {Reality} for {Prototyping} {Interactive} {Architecture}},
	isbn = {978-1-4503-5378-6},
	url = {http://doi.acm.org/10.1145/3152832.3156625},
	doi = {10.1145/3152832.3156625},
	abstract = {Even though, three-dimensional representations of architectural models exist, experiencing these models like one would experience a fully constructed building is still a major challenge. With Virtual Reality (VR) it is now possible to experience a number of scenarios in a virtual environment. Also prototyping interactive architecture elements, which might be very expensive, becomes possible. Thus, researchers and designers can already start to define user interfaces for interactive architectural elements, before they were even built. However, it is still an open question how exactly VR technologies can support experiencing interactive architecture. To answer this question, we compared experiencing three-dimensional architectural models and interactive architectural elements through a 2D screen \& mouse+keyboard navigation, an head mounted display (HMD) \& keyboard navigation, and an HMD \& walking for navigation. The results of our study show challenges and opportunities regarding the immersion of these experiences.},
	urldate = {2018-05-04},
	booktitle = {Proceedings of the 16th {International} {Conference} on {Mobile} and {Ubiquitous} {Multimedia}},
	publisher = {ACM},
	author = {Wolf, Katrin and Funk, Markus and Khalil, Rami and Knierim, Pascal},
	year = {2017},
	keywords = {virtual reality, interactive architecture, architectural, interactions},
	pages = {457--464},
	file = {ACM Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\FLI6XXCT\\Wolf et al. - 2017 - Using Virtual Reality for Prototyping Interactive .pdf:application/pdf}
}

@article{kronland-martinet_real-time_2008,
	title = {Real-{Time} {Perceptual} {Simulation} of {Moving} {Sources}: {Application} to the {Leslie} {Cabinet} and 3D {Sound} {Immersion}},
	volume = {2008},
	copyright = {2008 R. Kronland-Martinet and T.},
	issn = {1687-4722},
	shorttitle = {Real-{Time} {Perceptual} {Simulation} of {Moving} {Sources}},
	url = {https://asmp-eurasipjournals.springeropen.com/articles/10.1155/2008/849696},
	doi = {10.1155/2008/849696},
	abstract = {Perception of moving sound sources obeys different brain processes from those mediating the localization of static sound events. In view of these specificities, a preprocessing model was designed, based on the main perceptual cues involved in the auditory perception of moving sound sources, such as the intensity, timbre, reverberation, and frequency shift processes. This model is the first step toward a more general moving sound source system, including a system of spatialization. Two applications of this model are presented: the simulation of a system involving rotating sources, the Leslie Cabinet and a 3D sound immersion installation based on the sonification of cosmic particles, the Cosmophone.},
	language = {En},
	number = {1},
	urldate = {2018-05-05},
	journal = {EURASIP Journal on Audio, Speech, and Music Processing},
	author = {Kronland-Martinet, R. and Voinier, T.},
	month = dec,
	year = {2008},
	keywords = {perception, cues},
	pages = {849696},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\JCMIVJ4S\\Kronland-Martinet and Voinier - 2008 - Real-Time Perceptual Simulation of Moving Sources.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\U5L7KM6K\\849696.html:text/html}
}

@article{grimshaw_sound_nodate,
	title = {{SOUND} {AND} {IMMERSION} {IN} {THE} {FIRST}-{PERSON} {SHOOTER}},
	abstract = {One of the aims of modern First-Person Shooter (FPS) design is to provide an immersive experience to the player. This paper examines the role of sound in enabling such immersion and argues that, even in ‘realism’ FPS games, it may be achieved sonically through a focus on caricature rather than realism. The paper utilizes and develops previous work in which both a conceptual framework for the design and analysis of run and gun FPS sound is developed and the notion of the relationship between player and FPS soundscape as an acoustic ecology is put forward (Grimshaw and Schott 2007a; Grimshaw and Schott 2007b). Some problems of sound practice and sound reproduction in the game are highlighted and a conceptual solution is proposed.},
	language = {en},
	author = {Grimshaw, Mark},
	pages = {8},
	file = {Grimshaw - SOUND AND IMMERSION IN THE FIRST-PERSON SHOOTER.pdf:C\:\\Users\\bowli\\Zotero\\storage\\F2HRDVEX\\Grimshaw - SOUND AND IMMERSION IN THE FIRST-PERSON SHOOTER.pdf:application/pdf}
}

@article{ammi_intermodal_2015,
	title = {Intermodal audio–haptic intermodal display: improvement of communication and interpersonal awareness for collaborative search tasks},
	volume = {19},
	issn = {1359-4338, 1434-9957},
	shorttitle = {Intermodal audio–haptic intermodal display},
	url = {http://link.springer.com/article/10.1007/s10055-015-0273-5},
	doi = {10.1007/s10055-015-0273-5},
	abstract = {This paper studies a new sensorial approach to improving communication between partners during collaborative tasks taking place in abstract and non-visual virtual reality environments. The sensorial approach was investigated in the context of the search and identification of targets in a simplified 2D environment. It consists in finding a spatial configuration corresponding to a defined criterion such as a maximum, minimum, or defined score. During the collaborative search, users need to be aware of their results and also the results of their partners. In addition, they need to compare examined scores (e.g., docking score or physical value) with other results to make decisions. To support these features, an audio–haptic display was developed employing binaural audio with an intermodal stimuli synthesis design to improve the collaborative search. This rendering tool allows for simultaneous use of the audio and haptic channels which enables an efficient individual search and comparison of results. In addition, it improves the communication and activity coordination between the partners. An experiment was carried out to evaluate the contribution of the tool to improve the collaborative search of targets in a 2D non-visual environment. The results clearly show a significant improvement in performance and working efficiency with the audio–haptic display as compared to a traditional haptic-only condition. Moreover, we observed a reduction in the need for verbal communication during some steps of the search process. However, this approach introduces some communication conflicts during the steps presenting high-level interactions between partners which reduce the working efficiency of some groups.},
	language = {en},
	number = {3-4},
	urldate = {2018-05-06},
	journal = {Virtual Reality},
	author = {Ammi, Mehdi and Katz, Brian F. G.},
	month = nov,
	year = {2015},
	keywords = {cues, audio, collaboration},
	pages = {235--252},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\RVFVKJ7X\\Ammi and Katz - 2015 - Intermodal audio–haptic intermodal display improv.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\6HEG27DA\\s10055-015-0273-5.html:text/html}
}

@article{bowman_testbed_nodate,
	title = {Testbed {Evaluation} of {Virtual} {Environment} {Interaction} {Techniques}},
	abstract = {As immersive virtual environment (VE) applications become more complex, it is clear that we need a firm understanding of the principles of VE interaction. In particular, designers need guidance in choosing three-dimensional interaction techniques. In this paper, we present a systematic approach, testbed evaluation, for the assessment of interaction techniques for VEs. Testbed evaluation uses formal frameworks and formal experiments with multiple independent and dependent variables in order to obtain a wide range of performance data for VE interaction techniques. We present two testbed experiments, covering techniques for the common VE tasks of travel and object selection/manipulation. The results of these experiments allow us to form general guidelines for VE interaction, and to provide an empirical basis for choosing interaction techniques in VE applications. This has been shown to produce measurable usability gains in a real-world VE application.},
	language = {en},
	author = {Bowman, Doug A and Johnson, Donald B and Hodges, Larry F},
	pages = {8},
	file = {Bowman et al. - Testbed Evaluation of Virtual Environment Interact.pdf:C\:\\Users\\bowli\\Zotero\\storage\\HQRVKZRJ\\Bowman et al. - Testbed Evaluation of Virtual Environment Interact.pdf:application/pdf}
}

@article{salvendy_copyright_nodate,
	title = {Copyright © 2012 {John} {Wiley} \& {Sons}, {Inc}.},
	language = {en},
	author = {Salvendy, Gavriel},
	pages = {1736},
	file = {Salvendy - Copyright © 2012 John Wiley & Sons, Inc..pdf:C\:\\Users\\bowli\\Zotero\\storage\\U9NKFA3Q\\Salvendy - Copyright © 2012 John Wiley & Sons, Inc..pdf:application/pdf}
}

@article{rettie_connectedness_nodate,
	title = {Connectedness, {Awareness} and {Social} {Presence}.},
	language = {en},
	author = {Rettie, Ruth},
	keywords = {presence, awareness, connectedness, social presence},
	pages = {7},
	file = {Rettie - Connectedness, Awareness and Social Presence..pdf:C\:\\Users\\bowli\\Zotero\\storage\\FZACTMWX\\Rettie - Connectedness, Awareness and Social Presence..pdf:application/pdf}
}

@article{schubert_experience_2001-1,
	title = {The {Experience} of {Presence}: {Factor} {Analytic} {Insights}},
	volume = {10},
	issn = {1054-7460, 1531-3263},
	shorttitle = {The {Experience} of {Presence}},
	url = {http://www.mitpressjournals.org/doi/10.1162/105474601300343603},
	doi = {10.1162/105474601300343603},
	abstract = {Within an embodied cognition framework, it is argued that presence in a virtual environment (VE) develops from the construction of a spatial-functional mental model of the VE. Two cognitive processes lead to this model: the representation of bodily actions as possible actions in the VE, and the suppression of incompatible sensory input. It is hypothesized that the conscious sense of presence reﬂects these two components as spatial presence and involvement. This prediction was conﬁrmed in two studies (N ϭ 246 and N ϭ 296) assessing self-reports of presence and immersion experiences. Additionally, judgments of “realness” were observed as a third presence component. A second-order factor analysis showed a distinction between presence, immersion, and interaction factors. Building on these results, a thirteen-item presence scale consisting of three independent components was developed and veriﬁed using conﬁrmatory factor analyses across the two studies.},
	language = {en},
	number = {3},
	urldate = {2018-05-30},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Schubert, Thomas and Friedmann, Frank and Regenbrecht, Holger},
	month = jun,
	year = {2001},
	keywords = {presence, cognition, fear, holger},
	pages = {266--281},
	file = {Schubert et al. - 2001 - The Experience of Presence Factor Analytic Insigh.pdf:C\:\\Users\\bowli\\Zotero\\storage\\Z5L5QNL4\\Schubert et al. - 2001 - The Experience of Presence Factor Analytic Insigh.pdf:application/pdf}
}

@book{hermann_sonification_2011,
	address = {Berlin},
	title = {The sonification handbook},
	isbn = {978-3-8325-2819-5},
	language = {en},
	publisher = {Logos Verlag},
	editor = {Hermann, Thomas and Hunt, Andy and Neuhoff, John G.},
	year = {2011},
	note = {OCLC: ocn771999159},
	keywords = {Auditory perception, Computer sound processing, Psychoacoustics, Recording and reproducing Digital techniques, Sound},
	file = {TheSonificationHandbook-chapter18.pdf:C\:\\Users\\bowli\\Zotero\\storage\\5UYD7S36\\TheSonificationHandbook-chapter18.pdf:application/pdf}
}

@book{hermann_sonification_2011-1,
	address = {Berlin},
	title = {The sonification handbook},
	isbn = {978-3-8325-2819-5},
	language = {en},
	publisher = {Logos Verlag},
	editor = {Hermann, Thomas and Hunt, Andy and Neuhoff, John G.},
	year = {2011},
	note = {OCLC: ocn771999159},
	keywords = {Auditory perception, Computer sound processing, Psychoacoustics, Recording and reproducing Digital techniques, Sound},
	file = {Hermann et al. - 2011 - The sonification handbook.pdf:C\:\\Users\\bowli\\Zotero\\storage\\J3GHIUR8\\Hermann et al. - 2011 - The sonification handbook.pdf:application/pdf}
}

@article{gutwin_descriptive_2002,
	title = {A {Descriptive} {Framework} of {Workspace} {Awareness} for {Real}-{Time} {Groupware}},
	volume = {11},
	issn = {0925-9724, 1573-7551},
	url = {http://link.springer.com/10.1023/A:1021271517844},
	doi = {10.1023/A:1021271517844},
	abstract = {Supporting awareness of others is an idea that holds promise for improving the usability of real-time distributed groupware. However, there is little principled information available about awareness that can be used by groupware designers. In this article, we develop a descriptive theory of awareness for the purpose of aiding groupware design, focusing on one kind of group awareness called workspace awareness. We focus on how small groups perform generation and execution tasks in medium-sized shared workspaces – tasks where group members frequently shift between individual and shared activities during the work session. We have built a three-part framework that examines the concept of workspace awareness and that helps designers understand the concept for purposes of designing awareness support in groupware. The framework sets out elements of knowledge that make up workspace awareness, perceptual mechanisms used to maintain awareness, and the ways that people use workspace awareness in collaboration. The framework also organizes previous research on awareness and extends it to provide designers with a vocabulary and a set of ground rules for analysing work situations, for comparing awareness devices, and for explaining evaluation results. The basic structure of the theory can be used to describe other kinds of awareness that are important to the usability of groupware.},
	language = {en},
	number = {3-4},
	urldate = {2018-06-07},
	journal = {Computer Supported Cooperative Work (CSCW)},
	author = {Gutwin, Carl and Greenberg, Saul},
	month = sep,
	year = {2002},
	pages = {411--446},
	file = {Gutwin and Greenberg - 2002 - A Descriptive Framework of Workspace Awareness for.pdf:C\:\\Users\\bowli\\Zotero\\storage\\H6W5CAR5\\Gutwin and Greenberg - 2002 - A Descriptive Framework of Workspace Awareness for.pdf:application/pdf}
}

@inproceedings{gutwin_chalk_2011,
	title = {Chalk sounds: the effects of dynamic synthesized audio on workspace awareness in distributed groupware},
	isbn = {978-1-4503-0556-3},
	shorttitle = {Chalk sounds},
	url = {http://portal.acm.org/citation.cfm?doid=1958824.1958838},
	doi = {10.1145/1958824.1958838},
	abstract = {Awareness of other people’s activity is an important part of shared-workspace collaboration, and is typically supported using visual awareness displays such as radar views. These visual presentations are limited in that the user must be able to see and attend to the view in order to gather awareness information. Using audio to convey awareness information does not suffer from these limitations, and previous research has shown that audio can provide valuable awareness in distributed settings. In this paper we evaluate the effectiveness of synthesized dynamic audio information, both on its own and as an adjunct to a visual radar view. We developed a granular-synthesis engine that produces realistic chalk sounds for off-screen activity in a groupware workspace, and tested the audio awareness in two ways. First, we measured people’s ability to identify off-screen activities using only sound, and found that people are almost as accurate with synthesized sounds as with real sounds. Second, we tested dynamic audio awareness in a realistic groupware scenario, and found that adding audio to a radar view significantly improved awareness of off-screen activities in situations where it was difficult to see or attend to the visual display. Our work provides new empirical evidence about the value of dynamic synthesized audio in distributed groupware.},
	language = {en},
	urldate = {2018-06-08},
	publisher = {ACM Press},
	author = {Gutwin, Carl and Schneider, Oliver and Xiao, Robert and Brewster, Stephen},
	year = {2011},
	pages = {85},
	file = {Gutwin et al. - 2011 - Chalk sounds the effects of dynamic synthesized a.pdf:C\:\\Users\\bowli\\Zotero\\storage\\TPB5W7SW\\Gutwin et al. - 2011 - Chalk sounds the effects of dynamic synthesized a.pdf:application/pdf}
}

@misc{noauthor_situation_nodate,
	title = {Situation awareness global assessment technique ({SAGAT}) - {IEEE} {Conference} {Publication}},
	url = {https://ieeexplore-ieee-org.eaccess.ub.tum.de/abstract/document/195097/},
	urldate = {2018-06-10},
	file = {Situation awareness global assessment technique (SAGAT) - IEEE Conference Publication:C\:\\Users\\bowli\\Zotero\\storage\\2PZTCEUE\\195097.html:text/html}
}

@inproceedings{endsley_situation_1988,
	title = {Situation awareness global assessment technique ({SAGAT})},
	doi = {10.1109/NAECON.1988.195097},
	abstract = {Pilot-vehicle interface designs must be driven by the gaol of establishing and maintaining high pilot situation awareness. The situation-awareness global assessment technique (SAGAT), developed to assist in this process by providing an objective measure of pilot's situation awareness with any given aircraft design, is described. SAGAT is considered to represent a substantial improvement in the evaluation of pilot-vehicle interface designs, facilitating the development of cockpits which assist the pilot in surviving combat. A formal definition of situation awareness is presented a description of the SAGAT methology and a discussion of its validation},
	booktitle = {Proceedings of the {IEEE} 1988 {National} {Aerospace} and {Electronics} {Conference}},
	author = {Endsley, Mica R},
	month = may,
	year = {1988},
	keywords = {Aircraft, aircraft design, aircraft instrumentation, cockpits, Current measurement, Decision making, Displays, human factors, Human factors, Jacobian matrices, military systems, pilot-vehicle interface designs, Process design, SAGAT methology, situation-awareness global assessment technique, System performance, Vehicle driving},
	pages = {789--795 vol.3},
	file = {Endsley - 1988 - Situation awareness global assessment technique (S.pdf:D\:\\Documents\\studies\\ss18\\Thesis\\Literature\\Endsley - 1988 - Situation awareness global assessment technique (S.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\bowli\\Zotero\\storage\\GQYTRKUJ\\195097.html:text/html}
}

@article{eriksen_guide_nodate,
	title = {A {GUIDE} {TO} {WRITING} {YOUR} {STRATEGY} \& {ORGANIZATION} {MASTER} {THESIS}},
	language = {en},
	author = {Eriksen, Bo H},
	pages = {40},
	file = {Eriksen - A GUIDE TO WRITING YOUR STRATEGY & ORGANIZATION MA.pdf:C\:\\Users\\bowli\\Zotero\\storage\\9A2CWEQ8\\Eriksen - A GUIDE TO WRITING YOUR STRATEGY & ORGANIZATION MA.pdf:application/pdf}
}

@article{endsley_direct_nodate,
	title = {{DIRECT} {MEASUREMENT} {OF} {SITUATION} {AWARENESS}: {VALIDITY} {AND} {USE} {OF} {SAGAT}},
	language = {en},
	author = {Endsley, Mica R},
	keywords = {example, explained, sagat},
	pages = {21},
	file = {Endsley - DIRECT MEASUREMENT OF SITUATION AWARENESS VALIDIT.pdf:C\:\\Users\\bowli\\Zotero\\storage\\88A4MVJX\\Endsley - DIRECT MEASUREMENT OF SITUATION AWARENESS VALIDIT.pdf:application/pdf}
}

@article{kulik_virtual_2018,
	title = {Virtual {Valcamonica}: {Collaborative} {Exploration} of {Prehistoric} {Petroglyphs} and {Their} {Surrounding} {Environment} in {Multi}-{User} {Virtual} {Reality}},
	volume = {26},
	issn = {1054-7460, 1531-3263},
	shorttitle = {Virtual {Valcamonica}},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/pres_a_00297},
	doi = {10.1162/pres_a_00297},
	abstract = {In this article, we present a novel, multi-user, virtual reality environment for the interactive, collaborative 3D analysis of large 3D scans and the technical advancements that were necessary to build it: a multi-view rendering system for large 3D point clouds, a suitable display infrastructure, and a suite of collaborative 3D interaction techniques. The cultural heritage site of Valcamonica in Italy with its large collection of prehistoric rock-art served as an exemplary use case for evaluation. The results show that our output-sensitive level-of-detail rendering system is capable of visualizing a 3D dataset with an aggregate size of more than 14 billion points at interactive frame rates. The system design in this exemplar application results from close exchange with a small group of potential users: archaeologists with expertise in rockart. The system allows them to explore the prehistoric art and its spatial context with highly realistic appearance. A set of dedicated interaction techniques was developed to facilitate collaborative visual analysis. A multi-display workspace supports the immediate comparison of geographically distributed artifacts. An expert review of the ﬁnal demonstrator conﬁrmed the potential for added value in rock-art research and the usability of our collaborative interaction techniques.},
	language = {en},
	number = {03},
	urldate = {2018-06-11},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Kulik, Alexander and Kunert, André and Beck, Stephan and Matthes, Carl-Feofan and Schollmeyer, Andre and Kreskowski, Adrian and Fröhlich, Bernd and Cobb, Sue and D’Cruz, Mirabelle},
	month = may,
	year = {2018},
	pages = {297--321},
	file = {Kulik et al. - 2018 - Virtual Valcamonica Collaborative Exploration of .pdf:C\:\\Users\\bowli\\Zotero\\storage\\FG3XB7QY\\Kulik et al. - 2018 - Virtual Valcamonica Collaborative Exploration of .pdf:application/pdf}
}

@article{kulik_virtual_2018-1,
	title = {Virtual {Valcamonica}: {Collaborative} {Exploration} of {Prehistoric} {Petroglyphs} and {Their} {Surrounding} {Environment} in {Multi}-{User} {Virtual} {Reality}},
	volume = {26},
	issn = {1054-7460, 1531-3263},
	shorttitle = {Virtual {Valcamonica}},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/pres_a_00297},
	doi = {10.1162/pres_a_00297},
	abstract = {In this article, we present a novel, multi-user, virtual reality environment for the interactive, collaborative 3D analysis of large 3D scans and the technical advancements that were necessary to build it: a multi-view rendering system for large 3D point clouds, a suitable display infrastructure, and a suite of collaborative 3D interaction techniques. The cultural heritage site of Valcamonica in Italy with its large collection of prehistoric rock-art served as an exemplary use case for evaluation. The results show that our output-sensitive level-of-detail rendering system is capable of visualizing a 3D dataset with an aggregate size of more than 14 billion points at interactive frame rates. The system design in this exemplar application results from close exchange with a small group of potential users: archaeologists with expertise in rockart. The system allows them to explore the prehistoric art and its spatial context with highly realistic appearance. A set of dedicated interaction techniques was developed to facilitate collaborative visual analysis. A multi-display workspace supports the immediate comparison of geographically distributed artifacts. An expert review of the ﬁnal demonstrator conﬁrmed the potential for added value in rock-art research and the usability of our collaborative interaction techniques.},
	language = {en},
	number = {03},
	urldate = {2018-06-11},
	journal = {Presence: Teleoperators and Virtual Environments},
	author = {Kulik, Alexander and Kunert, André and Beck, Stephan and Matthes, Carl-Feofan and Schollmeyer, Andre and Kreskowski, Adrian and Fröhlich, Bernd and Cobb, Sue and D’Cruz, Mirabelle},
	month = may,
	year = {2018},
	pages = {297--321},
	file = {Kulik et al. - 2018 - Virtual Valcamonica Collaborative Exploration of .pdf:C\:\\Users\\bowli\\Zotero\\storage\\97BMFQ6B\\Kulik et al. - 2018 - Virtual Valcamonica Collaborative Exploration of .pdf:application/pdf}
}

@book{baldwin_auditory_2016,
	title = {Auditory {Cognition} and {Human} {Performance} : {Research} and {Applications}},
	isbn = {978-1-4665-5354-5},
	shorttitle = {Auditory {Cognition} and {Human} {Performance}},
	url = {https://www-taylorfrancis-com.eaccess.ub.tum.de/books/9781466553545},
	abstract = {Hearing and understanding sound — auditory processing — greatly enriches everyday life and enhances our ability to perform many tasks essential to survival. The},
	language = {en},
	urldate = {2018-06-12},
	publisher = {CRC Press},
	author = {Baldwin, Carryl L.},
	month = apr,
	year = {2016},
	doi = {10.1201/b11578},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\3XVKLYXJ\\Baldwin - 2016 - Auditory Cognition and Human Performance  Researc.pdf:application/pdf;Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\U2XHSHMG\\9781466553545.html:text/html}
}

@article{blattner_earcons_1989,
	title = {Earcons and {Icons}: {Their} {Structure} and {Common} {Design} {Principles}},
	volume = {4},
	issn = {0737-0024},
	shorttitle = {Earcons and {Icons}},
	url = {http://www.tandfonline.com/doi/abs/10.1207/s15327051hci0401_1},
	doi = {10.1207/s15327051hci0401_1},
	abstract = {In this article we examine earcons, which are audio messages used in the user-computer interface to provide information and feedback to the user about computer entities. (Earcons include messages and functions, as well as states and labels.) We identify some design principles that are common to both visual symbols and auditory messages, and discuss the use of representational and abstract icons and earcons. We give some examples of audio patterns that may be used to design modules for earcons, which then may be assembled into larger groupings called families. The modules are single pitches or rhythmicized sequences of pitches called motives. The families are constructed about related motives that serve to identify a family of related messages. Issues concerned with learning and remembering earcons are discussed.},
	language = {en},
	number = {1},
	urldate = {2018-06-12},
	journal = {Human-Computer Interaction},
	author = {Blattner, Meera and Sumikawa, Denise and Greenberg, Robert},
	month = mar,
	year = {1989},
	keywords = {earcons, sumikawa},
	pages = {11--44},
	file = {Blattner et al. - 1989 - Earcons and Icons Their Structure and Common Desi.pdf:C\:\\Users\\bowli\\Zotero\\storage\\FG4NP3AD\\Blattner et al. - 1989 - Earcons and Icons Their Structure and Common Desi.pdf:application/pdf}
}

@inproceedings{poupyrev_go-go_1996,
	address = {New York, NY, USA},
	series = {{UIST} '96},
	title = {The {Go}-go {Interaction} {Technique}: {Non}-linear {Mapping} for {Direct} {Manipulation} in {VR}},
	isbn = {978-0-89791-798-8},
	shorttitle = {The {Go}-go {Interaction} {Technique}},
	url = {http://doi.acm.org/10.1145/237091.237102},
	doi = {10.1145/237091.237102},
	urldate = {2018-06-25},
	booktitle = {Proceedings of the 9th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Poupyrev, Ivan and Billinghurst, Mark and Weghorst, Suzanne and Ichikawa, Tadao},
	year = {1996},
	keywords = {virtual reality, 3D user interface, user interface metaphor},
	pages = {79--80},
	file = {ACM Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\HN77S52X\\Poupyrev et al. - 1996 - The Go-go Interaction Technique Non-linear Mappin.pdf:application/pdf}
}

@phdthesis{lampe_cdp//vr-sketching_2017,
	title = {{CDP}//{VR}-{Sketching} to {Support} {Creative} {Thinking} in {Urban} {Planning}},
	url = {file:\\\D:\Documents\studies\ss18\Thesis\Literature\Sofia -- CDPVR-Sketching to Support Creative Thinking in Urban Planning -- BA-print-final.pdf},
	language = {En},
	school = {Technical University of Munich},
	author = {Lampe, Sofia},
	month = oct,
	year = {2017},
	file = {Lampe - 2017 - CDPVR-Sketching to Support Creative Thinking in .pdf:D\:\\Documents\\studies\\ss18\\Thesis\\Literature\\Lampe - 2017 - CDPVR-Sketching to Support Creative Thinking in .pdf:application/pdf}
}

@book{jr_3d_2017,
	title = {3D {User} {Interfaces}: {Theory} and {Practice}},
	isbn = {978-0-13-403446-1},
	shorttitle = {3D {User} {Interfaces}},
	abstract = {The Complete, Up-To-Date Guide to Building Great 3D User Interfaces for Any Application  3D interaction is suddenly everywhere. But simply using 3D input or displays isn’t enough: 3D interfaces must be carefully designed for optimal user experience. 3D User Interfaces: Theory and Practice, Second Edition is today’s most comprehensive primary reference to building state-of-the-art 3D user interfaces and interactions. Five pioneering researchers and practitioners cover the full spectrum of emerging applications, techniques, and best practices. The authors combine theoretical foundations, analysis of leading devices, and empirically validated design guidelines. This edition adds two new chapters on human factors and general human-computer interaction—indispensable foundational knowledge for building any 3D user interface. It also demonstrates advanced concepts at work through two running case studies: a first-person VR game and a mobile augmented reality application. Coverage Includes  3D user interfaces: evolution, elements, and roadmaps Key applications: virtual and augmented reality (VR, AR), mobile/wearable devices What 3D UI designers should know about human sensory systems and cognition ergonomics How proven human-computer interaction techniques apply to 3D UIs 3D UI output hardware for visual, auditory, and haptic/ tactile systems Obtaining 3D position, orientation, and motion data for users in physical space 3D object selection and manipulation Navigation and wayfinding techniques for moving through virtual and physical spaces Changing application state with system control techniques, issuing commands, and enabling other forms of user input Strategies for choosing, developing, and evaluating 3D user interfaces Utilizing 2D, “magic,” “natural,” multimodal, and two-handed interaction The future of 3D user interfaces: open research problems and emerging technologies},
	language = {en},
	publisher = {Addison-Wesley Professional},
	author = {Jr, Joseph J. LaViola and Kruijff, Ernst and McMahan, Ryan P. and Bowman, Doug and Poupyrev, Ivan P.},
	month = apr,
	year = {2017},
	note = {Google-Books-ID: fxWSDgAAQBAJ},
	keywords = {Computers / Software Development \& Engineering / General, Computers / User Interfaces}
}

@article{churchill_collaborative_1998,
	title = {Collaborative virtual environments: {An} introductory review of issues and systems},
	volume = {3},
	issn = {1359-4338, 1434-9957},
	shorttitle = {Collaborative virtual environments},
	url = {http://link.springer.com/10.1007/BF01409793},
	doi = {10.1007/BF01409793},
	abstract = {A Collaborative Virtual Environment or CVE is a distributed, virtual reaEitythat is designed to support collaborative activities, As such, CVEs provide a potentiaIly infinite, graphically malised digital landscape within which multiple users can interact with each other and with simple or complex data representations. CVEs are increasingly being used to support collaborative work between geographically separated and between collocated collaborators. CVEsvary in the sophistication of the data and embodiment representations employed and in the level of interactivity supported. It is clear that systems which are intended to support collaborative activities should be designed with explicit consideration of the tasks to be achieved and the intended users' social and cognitive characteristics. In this paper, we detail a number Qf existing systems and appfications, but first discuss the nature of collaborative and cooperative work activities and consider the place of virtual reality systems in supporting such coTlaborativework. Following this, we discuss some future research directions.},
	language = {en},
	number = {1},
	urldate = {2018-10-25},
	journal = {Virtual Reality},
	author = {Churchill, E. F. and Snowdon, D.},
	month = mar,
	year = {1998},
	pages = {3--15},
	file = {Churchill and Snowdon - 1998 - Collaborative virtual environments An introductor.pdf:C\:\\Users\\bowli\\Zotero\\storage\\82IMLC4Q\\Churchill and Snowdon - 1998 - Collaborative virtual environments An introductor.pdf:application/pdf}
}

@misc{noauthor_virtual_2018,
	title = {Virtual reality},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Virtual_reality&oldid=864247961},
	abstract = {Virtual reality (VR) is an interactive computer-generated experience taking place within a simulated environment, that incorporates mainly auditory and visual, but also other types of sensory feedback like haptic. This immersive environment can be similar to the real world or it can be fantastical, creating an experience that is not possible in ordinary physical reality. Augmented reality systems may also be considered a form of VR that layers virtual information over a live camera feed into a headset or through a smartphone or tablet device giving the user the ability to view three-dimensional images.
Current VR technology most commonly uses virtual reality headsets or multi-projected environments, sometimes in combination with physical environments or props, to generate realistic images, sounds and other sensations that simulate a user's physical presence in a virtual or imaginary environment. A person using virtual reality equipment is able to "look around" the artificial world, move around in it, and interact with virtual features or items. The effect is commonly created by VR headsets consisting of a head-mounted display with a small screen in front of the eyes, but can also be created through specially designed rooms with multiple large screens.
VR systems that include transmission of vibrations and other sensations to the user through a game controller or other devices are known as haptic systems. This tactile information is generally known as force feedback in medical, video gaming and military training applications.},
	language = {en},
	urldate = {2018-10-26},
	journal = {Wikipedia},
	month = oct,
	year = {2018},
	note = {Page Version ID: 864247961},
	file = {Snapshot:C\:\\Users\\bowli\\Zotero\\storage\\NRJXVMRF\\index.html:text/html}
}

@article{sandell_review_1996,
	title = {Review of {Auditory} {Display}: {Sonification}, {Audification}, and {Auditory} {Interfaces}},
	volume = {13},
	issn = {0730-7829},
	shorttitle = {Review of {Auditory} {Display}},
	url = {https://www.jstor.org/stable/40285703},
	doi = {10.2307/40285703},
	number = {4},
	urldate = {2018-10-28},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Sandell, Gregory J.},
	collaborator = {Kramer, Gregory},
	year = {1996},
	pages = {583--591}
}

@article{sandell_auditory_1996,
	title = {"{Auditory} {Display}: {Sonification}, {Audification}, and {Auditory} {Interfaces}", edited by {Gregory} {Kramer} ({Book} {Review})},
	volume = {13},
	issn = {0730-7829},
	shorttitle = {"{Auditory} {Display}},
	url = {http://search.proquest.com/docview/1300628117/citation/ECB7491BA2A34838PQ/1},
	language = {English},
	number = {4},
	urldate = {2018-10-28},
	journal = {Music Perception; Berkeley, Calif.},
	author = {Sandell, Gregory J.},
	year = {1996},
	keywords = {Music},
	pages = {583--591},
	file = {Full Text PDF:C\:\\Users\\bowli\\Zotero\\storage\\CKZ46NIG\\Sandell - 1996 - Auditory Display Sonification, Audification, and.pdf:application/pdf}
}

@article{redfern_collaborative_nodate,
	title = {Collaborative {Virtual} {Environments} to {Support} {Communication} and {Community} in {Internet}-{Based} {Distance} {Education}},
	abstract = {In this paper we discuss the use of modern information and communication technologies for distance education (DE) purposes. We argue that current technologies and implementations do not adequately support the key concepts of communication and community that many practitioners believe to be important, particularly if modern pedagogies such as constructivism are to be supported. We propose that collaborative virtual environments (CVEs) are appropriate tools for improving DE, and we discuss the current developments in the areas of CVEs in particular and in computer supported co-operative work (CSCW) in general. We also note those areas in which the majority of CVEs implemented to date have not reached their full potential for DE support, discuss current thought regarding online community, and outline a proposed CVE-based system for DE.},
	language = {en},
	journal = {Collaborative Virtual Environments},
	author = {Redfern, Sam and Naughton, Niall},
	pages = {11},
	file = {Redfern and Naughton - Collaborative Virtual Environments to Support Comm.pdf:C\:\\Users\\bowli\\Zotero\\storage\\H8F5RLA6\\Redfern and Naughton - Collaborative Virtual Environments to Support Comm.pdf:application/pdf}
}

@article{bannon_perspectives_nodate,
	title = {Perspectives on {CSCW}: {From} {HCI} and {CMC} to {CSCW}},
	abstract = {This paper provides a perspective on the emergence of a new field of research entitled Computer Supported Cooperative Work (CSCW), tracing it to a growing realization within several communities of problems in existing approaches. The focus in this particular paper is on problems within the human-computer interaction (HCI) field, and on how the broader range of disciplinary perspectives evident in CSCW research can be seen to offer some resolution, or at least offer some new approaches, to the "crises" within the field. Along the way, we will also make some reference to another loose research community grouped under the heading of computer-mediated communication (CMC), and show how this work can be seen as a contributory step towards the development of the CSCW research field. The purpose of the paper is thus to help place the emergence of this "new" field within a framework that outlines both continuities and discontinuities with other established research traditions.},
	language = {en},
	year = {1992},
	author = {Bannon, Liam J},
	pages = {13},
	file = {Bannon - Perspectives on CSCW From HCI and CMC to CSCW.pdf:C\:\\Users\\bowli\\Zotero\\storage\\4P4BM9QF\\Bannon - Perspectives on CSCW From HCI and CMC to CSCW.pdf:application/pdf}
}